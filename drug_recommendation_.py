# -*- coding: utf-8 -*-
"""Drug  Recommendation .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gvWxsQYKbuVwsLxN91U28hoVg2Uu8i-R
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import itertools
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
from sklearn.linear_model import PassiveAggressiveClassifier
pd.set_option('display.max_rows', None)

df=pd.read_csv('/content/drive/MyDrive/drugsComTrain_raw.tsv',sep='\t')

df.head()

df.condition.value_counts()

df_train=df[(df['condition']=='Birth Control')|(df['condition']=='Depression')| (df['condition']=='High Blood Pressure')|(df['condition']=='Pain')]

df.shape

df_train.shape

from google.colab import drive
drive.mount('/content/drive')

X=df_train.drop(['Unnamed: 0', 'drugName', 'rating', 'date', 'usefulCount'],axis =1)

#EDA

X.condition.value_counts()

X.head()

X_birth=X[X['condition']=='Birth Control']
X_dep=X[X['condition']=='Depression']
X_bp=X[X['condition']=='High Blood Pressure']
X_pain=X[X['condition']=='Pain']

from wordcloud import WordCloud
plt.figure(figsize=(20,20))
wc=WordCloud(max_words=1000,width=1600,height=800).generate(" ".join(X_birth.review))
plt.imshow(wc , interpolation='bilinear')
plt.title('Word count for Birth Control', fontsize =16)

from wordcloud import WordCloud
plt.figure(figsize=(20,20))
wc=WordCloud(max_words=1000,width=1600,height=800).generate(" ".join(X_dep.review))
plt.imshow(wc , interpolation='bilinear')
plt.title('Word count for Depression', fontsize =16)

from wordcloud import WordCloud
plt.figure(figsize=(20,20))
wc=WordCloud(max_words=1000,width=1600,height=800).generate(" ".join(X_bp.review))
plt.imshow(wc , interpolation='bilinear')
plt.title('Word count for High Blood Pressure', fontsize =16)

from wordcloud import WordCloud
plt.figure(figsize=(20,20))
wc=WordCloud(max_words=500,width=1600,height=800).generate(" ".join(X_pain.review))
plt.imshow(wc , interpolation='bilinear')
plt.title('Word count for Pain', fontsize =14)

# Data Preprocessing

X['review'][2]

X['review'][11]

for i ,col in enumerate(X.columns):
  X.iloc[:,i]=X.iloc[:,i].str.replace('"',' ')

X.head()

#Stop words

from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
stop =stopwords.words('english')

stop

#Lemmatization

from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
porter =PorterStemmer()
nltk.download('wordnet')
lemmatizer=WordNetLemmatizer()

print(porter.stem('sportingly'))
print(lemmatizer.lemmatize('sportingly'))

from bs4 import BeautifulSoup
import re

def review_to_words(raw_review):
    # 1. Delete HTML
    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()

    # 2. Make a space
    letters_only = re.sub("[^a-zA-Z]", " ", review_text)

    # 3. Lower Letters
    words = letters_only.lower().split()

    # 4. Stopwords
    stop = set(stopwords.words("english"))
    meaningful_words = [w for w in words if not w in stop]

    # 5. Lemmatization
    lemmatizer = WordNetLemmatizer()
    lemmatize_words = [lemmatizer.lemmatize(w) for w in meaningful_words]

    # 6. space join words
    return " ".join(lemmatize_words)

# Apply cleaning function to dataset
X['review_clean'] = X['review'].apply(review_to_words)

X.head()

X_feat = X['review_clean']
y = X['condition']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_feat, y, stratify=y, test_size=0.2, random_state=0)

from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print("Confusion matrix, without normalization")

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

#Bag of words

count_vectorizer = CountVectorizer(stop_words='english')
count_train = count_vectorizer.fit_transform(X_train)
count_test = count_vectorizer.transform(X_test)

count_train

# Machine Learning Model: Naive Bayes
mnb = MultinomialNB()
mnb.fit(count_train, y_train)
pred = mnb.predict(count_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy: %0.3f" % score)

cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])
plot_confusion_matrix(cm, classes=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])

# Machine Learning Model: Passive Aggressive Classifier
from sklearn.linear_model import PassiveAggressiveClassifier
passive = PassiveAggressiveClassifier()
passive.fit(count_train, y_train)
pred = passive.predict(count_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy: %0.3f" % score)

cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])
plot_confusion_matrix(cm, classes=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])

#Tfidf

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)
tfidf_train_2 = tfidf_vectorizer.fit_transform(X_train)
tfidf_test_2 = tfidf_vectorizer.transform(X_test)

# Naive Bayes_Tfidf
mnb_tf = MultinomialNB()
mnb_tf.fit(tfidf_train_2, y_train)
pred = mnb_tf.predict(tfidf_test_2)
score = metrics.accuracy_score(y_test, pred)
print("accuracy: %0.3f" % score)

cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])
plot_confusion_matrix(cm, classes=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])

# Passive Aggressive Classifier _TFidf
tfidf_vectorizer2 = TfidfVectorizer(stop_words='english', max_df=0.8)
tfidf_train_2 = tfidf_vectorizer.fit_transform(X_train)
tfidf_test_2 = tfidf_vectorizer.transform(X_test)

passive_tf = PassiveAggressiveClassifier()
passive_tf.fit(tfidf_train_2, y_train)
pred = passive_tf.predict(tfidf_test_2)
score = metrics.accuracy_score(y_test, pred)
print("accuracy: %0.3f" % score)
cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])
plot_confusion_matrix(cm, classes=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])

#Tfid Bigram Approach

tfidf_vectorizer2 = TfidfVectorizer(stop_words='english', max_df=0.8, ngram_range=(1,2))
tfidf_train_2 = tfidf_vectorizer.fit_transform(X_train)
tfidf_test_2 = tfidf_vectorizer.transform(X_test)

passive_tf = PassiveAggressiveClassifier()
passive_tf.fit(tfidf_train_2, y_train)
pred = passive_tf.predict(tfidf_test_2)
score = metrics.accuracy_score(y_test, pred)
print("accuracy: %0.3f" % score)
cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])
plot_confusion_matrix(cm, classes=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])

# TFidf Trigram Approach

tfidf_vectorizer3 = TfidfVectorizer(stop_words='english', max_df=0.8, ngram_range=(1,3))
tfidf_train_3 = tfidf_vectorizer.fit_transform(X_train)
tfidf_test_3 = tfidf_vectorizer.transform(X_test)

passive_tf = PassiveAggressiveClassifier()
passive_tf.fit(tfidf_train_3, y_train)
pred = passive_tf.predict(tfidf_test_3)
score = metrics.accuracy_score(y_test, pred)
print("accuracy: %0.3f" % score)
cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])
plot_confusion_matrix(cm, classes=['Birth Control', 'Depression', 'Pain', 'High Blood Pressure'])

# prompt: find the most important features for all 4 rows selected also print classlabels and coefficient values for each

# Assuming 'passive_tf' is the trained PassiveAggressiveClassifier model
# and 'tfidf_vectorizer3' is the TfidfVectorizer used for it.

# You need to fit tfidf_vectorizer3 to your training data
tfidf_vectorizer3.fit(X_train) #This line fits the vectorizer to the training data.

feature_names = tfidf_vectorizer3.get_feature_names_out()
# Get the coefficients for each class
coefficients = passive_tf.coef_

# Number of top features to display for each class
top_features = 10

# Print top features for each class
for i, class_label in enumerate(['Birth Control', 'Depression', 'Pain', 'High Blood Pressure']):
    top_positive_coefficients = np.argsort(coefficients[i])[-top_features:]
    top_negative_coefficients = np.argsort(coefficients[i])[:top_features]

    print(f"Class: {class_label}")
    print("Top Positive Coefficients:")
    for j in top_positive_coefficients:
      print(f"  {feature_names[j]}: {coefficients[i][j]}")

    print("\nTop Negative Coefficients:")
    for j in top_negative_coefficients:
        print(f"  {feature_names[j]}: {coefficients[i][j]}")
    print("\n")

# Sample Prediction

X.tail()

from sklearn.feature_extraction.text import TfidfVectorizer
text ='I have only been on Tekturna for 9 days. The effect was immediate. I am also on a calcium channel blocker (Tiazac) and hydrochlorothiazide. I was put on Tekturna because of palpitations experienced with Diovan (ugly drug in my opinion, same company produces both however). The palpitations were pretty bad on Diovan, 24 hour monitor by EKG etc. After a few days of substituting Tekturna for Diovan, there are no more palpitations.	'
# Put the string inside a list to make it an iterable
test=tfidf_vectorizer.transform([text])  # Changed this line
pred1=passive_tf.predict(test)[0]
print(pred1)

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/drugsComTrain_raw.tsv', sep='\t')

# Preprocess the data by combining 'condition' and 'review' columns for better context
df['text'] = df['condition'].fillna('') + " " + df['review'].fillna('')

# Vectorize the combined text data (condition + review)
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['text'])

# Function to predict condition and recommend top 3 drugs based on symptoms
def recommend_drugs_for_symptoms(symptoms, top_n=3):
    # Transform the user-provided symptoms
    symptoms_vec = tfidf.transform([symptoms])

    # Compute cosine similarity between the symptoms and all entries in the dataset
    cosine_similarities = cosine_similarity(symptoms_vec, tfidf_matrix).flatten()

    # Add cosine similarity scores to the DataFrame
    df['similarity'] = cosine_similarities

    # Find the most relevant condition based on highest similarity
    most_relevant_condition = df.loc[df['similarity'].idxmax(), 'condition']

    # Filter the dataset for the identified condition
    condition_df = df[df['condition'] == most_relevant_condition]

    # Sort by similarity, rating, and usefulCount to find top drugs
    recommended_drugs = condition_df.sort_values(by=['similarity', 'rating', 'usefulCount'], ascending=[False, False, False])

    # Select top N drugs and their details
    top_drugs = recommended_drugs[['drugName', 'condition', 'review', 'rating', 'usefulCount']].head(top_n)

    return most_relevant_condition, top_drugs

# Example usage
symptoms_input = "feeling anxious, difficulty sleeping, restlessness"
predicted_condition, top_drugs = recommend_drugs_for_symptoms(symptoms_input)
print("Predicted Condition:", predicted_condition)
print("Top recommended drugs for", predicted_condition)
print(top_drugs)

# Import required libraries
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import joblib

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/drugsComTrain_raw.tsv', sep='\t')
df['text'] = df['condition'].fillna('') + " " + df['review'].fillna('')

# Train TF-IDF vectorizer
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['text'])

# Save the TF-IDF vectorizer and the dataset
joblib.dump(tfidf, '/content/tfidf_vectorizer.joblib')
joblib.dump(df, '/content/drugs_dataset.joblib')

from google.colab import files

# Download the saved vectorizer
files.download('/content/tfidf_vectorizer.joblib')

# Download the saved dataset
files.download('/content/drugs_dataset.joblib')



